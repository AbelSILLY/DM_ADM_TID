---
title: "DM_TID"
output: html_document
date: "2023-10-24"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
Entropie<-function(X=vector){
  e =-sum(X*log(X))
  e
}
print(Entropie((tableau$effectif)/sum(effectif)))
```


# Exercice 1:

```{r}
#Déclaration des variables
Q<-c(0.28,0.43,0.21,0.07,0.01)
B1<-c(0.4096,0.4096,0.1536,0.0256,0.0016) #B(4,0.2)
B2<-c(0.3164063,0.421875,0.2109375,0.046875,0.00390625) #B(4,0.25)
B3<-c(0.2401,0.4116,0.2646,0.0756,0.0081) #B(4,0.3)
B4<-c(0.1785063,0.384475,0.3105375,0.111475,0.01500625) #B(4,0.35)
```

## Question 1

```{r}
K_Q_B1 <-sum(log(Q/B1)*Q)
print(K_Q_B1)
K_Q_B2 <-sum(log(Q/B2)*Q)
print(K_Q_B2)
K_Q_B3 <-sum(log(Q/B3)*Q)
print(K_Q_B3)
K_Q_B4 <-sum(log(Q/B4)*Q)
print(K_Q_B4)
```
La distribution qui se rapproche le plus au sens de Kullbach Leibler est la B(4,0.3).

## Question 2

```{r}
D_CHI2_Q_B1 <-sum(((Q-B1)^2)/Q)
print(D_CHI2_Q_B1)
D_CHI2_Q_B2 <-sum(((Q-B2)^2)/Q)
print(D_CHI2_Q_B2)
D_CHI2_Q_B3 <-sum(((Q-B3)^2)/Q)
print(D_CHI2_Q_B3)
D_CHI2_Q_B4 <-sum(((Q-B4)^2)/Q)
print(D_CHI2_Q_B4)
```
La distribution qui se rapproche le plus de Q au sens du $\chi^2$ est cette fois ci la B(4,0.25)

# Exercice 2:

```{r}
profession <- c(rep('Agriculteurs',2),rep('Artisans',2),rep('Cadres',2),rep('Prof_int',2),rep('Employes',2),rep('Ouvriers'),2)
age <-c(rep('15-29',12),rep('30-39',12),rep('40-49',12),rep('50-59',12),rep('60-plus',12))
sexe <-rep(c('Femmes','Hommes'),15)
effectif<-c(27.8,24.2,117.4,79.2,564.9,315.7,1353.7,613.3,1570.9,476,
1271.6,1085.8,70,56.2,357.9,258.4,1209,
685.3,1840.7,834.7,1605.6,449.5,1285.9,1068.4,119.6,89.8,
556.1,387.2,1429.5,853.2,1895,
915.7,1880.9,416,1362.7,1065.5,187.1,138,525.8,378.7,
1161.6,719,1507.8,755.9,1819.6,329.8,
1300.4,987.9,76.9,43.4,184.8,128.7,360,240.1,256.2,123.7,
397,58.3,180.5,130.1)
tableau <- data.frame(age,profession,sexe, effectif)
print(tableau)

MA<-aggregate(effectif ~ age, data=tableau, sum)
print(MA)
MAS<-aggregate(effectif ~ age+sexe, data=tableau, sum)
print(MAS)
```

## Question 1

```{r}
XF<-rbind(
  c(27.8, 70, 119.6, 187.1, 76.9),
  c(117.4, 357.9, 556.1, 525.8, 184.8),
  c(564.9, 1209,	1429.5,	1161.6, 360),
  c(1353.7,	1840.7,	1895,	1507.8,	256.2),
  c(1570.9, 1605.6, 1880.9, 1819.6, 397),
  c(1271.6, 1285.9, 1362.7, 1300.4, 180.5)
)#matrice des catégories socioprofessionnelles par âge pour les femmes
XH<-rbind(
  c(24.2, 56.2, 89.8, 138, 43.4),
  c(79.2, 258.4, 387.2, 378.7, 128.7),
  c(315.7, 685.3, 853.2, 719, 240.1),
  c(613.3, 834.7, 915.7, 755.9, 123.7),
  c(476, 449.5, 416, 329.8, 58.3),
  c(1085.8, 1068.4, 1065.5, 987.9, 130.1)
)#matrice des catégories socioprofessionnelles par âge pour les hommes
```

```{r}
CA<-XH+XF #matrice des catégories socioprofessionnelles par âge indépendemment du sexe
print(CA)
P_c<-rep(0,6) #vecteur distribution de C
for (i in 1:6){
P_c[i]<-sum(CA[i,])
}
P_c<-(P_c)/sum(CA)
print(P_c)
H_C<-sum(-P_c*log(P_c)) #entropie de C
print(H_C)
```

```{r}
#Matrice AxS
AS<-matrix(0,nrow=2,ncol=5)# les lignes représentent le sexe, et les colonnes les tranches d'age
print(AS)
for(i in 1:5){
  AS[1,i]<-sum(XF[,i])
  AS[2,i]<-sum(XH[,i])
}
print(AS) #au coeff (i,j) on a le nombre de travailleurs pour le sexe i et la tranche d'age j
print(sum(AS[1,])) #nombre de travailleuses femmes
print(sum(AS[2,])) #nombre de travailleurs hommes
AS<-AS/sum(AS) 
print(AS) # au coeff (i,j) on a la proba de tirer un travailleur du sexe i et de la tranche d'age j
p_f<-sum(AS[1,]) #proba de tirer une femme
p_h<-sum(AS[2,]) #proba de tirer un homme
H_AS<--(sum(AS*log(AS)))#entropie de AxS
print(H_AS)
```

```{r}
T<-rbind(XF,XH)
T<-as.data.frame(T)
rownames(T)<-c("Agriculteur femme","Artisan femme", "Cadre femme","Profession i femme","Employés femme","Ouvrier femme","Agriculteur homme","Artisan homme", "Cadre homme","Profession i homme","Employés homme","Ouvrier homme")
colnames(T)<-c("DE 15 à 29 ans","DE 30 à 39 ans","DE 40 à 49 ans","DE 50 à 59 ans","60 ans et plus")
print(T)
T<-T/sum(T)
print(T)
H_T<--(sum(T*log(T)))#entropie de (C,(AxS))
print(H_T)
```

```{r}
print(H_C)
print(H_AS)
I_C_AS<-H_C + H_AS - H_T #I(C,(AxS))
print(I_C_AS)
```
```{r}
H_S<- -(p_f*log(p_f) + p_h*log(p_h)) #entropie de S
print(H_S)
```

```{r}
print(CA)
CA<-CA/sum(CA)
H_CA<- -sum(CA*log(CA)) #entropie de (CxA)
print(H_CA)
```

```{r}
I_S_CA<- H_S + H_CA - H_T
print(I_S_CA)
```

```{r}
M<-XF+XH
print(M)
A<-rep(0,5)
for(j in 1:5){
  A[j]<-sum(M[,j])
}
print(A)
A<-A/sum(A) #distribution de l'age
print(A) 
H_A<--sum(A*log(A))
print(H_A)
```

```{r}
#print(XF)
#print(XH)
CF<-rep(0,6)
CH<-rep(0,6)
for(i in 1:6){
  CF[i]<-sum(XF[i,])
  CH[i]<-sum(XH[i,])
}
print(CF)
print(CH)
CS<-rbind(t(CF),t(CH))
#print(t(CS))
CS<-t(CS)
colnames(CS)<-c("Femme","Homme")
print(CS)
CS<-CS/sum(CS) #coeff (i,j)= proba de tirer un travailleur de la classe socioprofessionnelle i et du sexe j
H_CS<--sum(CS*log(CS))
print(H_CS)
```

```{r}
I_A_CS<-H_A + H_CS - H_T
print(I_A_CS)
print(max(I_A_CS,I_C_AS,I_S_CA))
```
La plus grande info mutuelle est I(C,(AxS)). On préfèrera donc conditionner par la catégorie socioprofessionnelle.

## Question 2

Formule: I(X,Y)=H(X) + H(Y) - H(X,Y)

```{r}
I_CA<- H_C + H_A - H_CA
print(I_CA)
I_AS<-H_A + H_S - H_AS
print(I_AS)
I_CS<- H_C + H_S - H_CS
print(I_CS)
```

```{r}
I_A<- I_CA + I_AS
I_S<- I_AS + I_CS
I_C<- I_CA + I_CS
print(I_A)
print(I_S)
print(I_C)
```
On commmence l'arbre avec la variable de catégorie socioprofessionnelle
Comme I(A,S)=I(S,A) le choix de la seconde variable de ségmentation n'a pas d'importance.


# Exercice 3

```{r}
A<-rbind(c(2, 6, 8, 5, 1),c(27, 10, 8, 5, 1))
print(A)
X<-rep(0,5)
for(i in 1:5){
  X[i]<-sum(A[,i])
}
print(X)
```

```{r}
# recodage de X en 2 classes
RX1<-c(X[1],sum(X[2:5]))/73
print(RX1)
RX2<-c(X[1]+X[2],sum(X[3:5]))/73
print(RX2)
RX3<-c(sum(X[1:3]),sum(X[4],X[5]))/73
print(RX3)
RX4<-c(sum(X[1:4]),X[5])/73
print(RX4)

#calcul d'entropie
print("calcul d'entropie:")
H_RX1<--sum(RX1*log(RX1))
print(H_RX1) #meilleur recodage
H_RX2<--sum(RX2*log(RX2))
print(H_RX2)
H_RX3<--sum(RX3*log(RX3))
print(H_RX3)
H_RX4<--sum(RX4*log(RX4))
print(H_RX4)

```

```{r}
# recodage de X en 3 classes
print(X)
R1<-c(29,16,16+10+2)/73
print(R1)
R2<-c(29,16+16,10+2)/73
print(R2)
R3<-c(29,16+16+10,2)/73
print(R3)
R4<-c(29+16,16+10,2)/73
print(R4)
R5<-c(29+16+16,10,2)/73
print(R5)
R6<-c(29+16,16,10+2)/73
print(R6)

#calcul d'entropie:
H_R1<--sum(R1*log(R1))
print(H_R1)#meilleur recodage
H_R2<--sum(R2*log(R2))
print(H_R2)
H_R3<--sum(R3*log(R3))
print(H_R3)
H_R4<--sum(R4*log(R4))
print(H_R4)
H_R5<--sum(R5*log(R5))
print(H_R5)
H_R6<--sum(R6*log(R6))
print(H_R6)

print(max(H_R1,H_R2,H_R3,H_R4,H_R5,H_R6))
print(R1*73)
```

